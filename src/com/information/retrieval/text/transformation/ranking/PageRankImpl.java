package com.information.retrieval.text.transformation.ranking;

import com.information.retrieval.fileio.FileUtility;
import com.information.retrieval.text.transformation.builder.GraphBuilder;
import com.information.retrieval.text.transformation.pojo.Graph;

import java.util.*;
import java.util.stream.Collectors;

/**
 * Class responsible for initializing vectors and executing
 * PageRank algorithm
 */
public class PageRankImpl implements PageRank {

    private Graph graph;
    private Map<String, Double> pageRankScore;
    private double teleportationFactor = 1.0;

    public PageRankImpl(String graphFileLocation) throws Exception {
        retrieveGraph(graphFileLocation);
        pageRankScore = new LinkedHashMap<>();
    }

    public Graph getGraph() {
        return graph;
    }

    // Initializes the map with zero values for each DocID
    private void initializePageRank() {
        graph.getInLinkMap().forEach((docID , inLink) -> {
            pageRankScore.put(docID , 0.0);
        });
    }

    // Call this function for custom teleportation factor. Default value = 1.0
    public void setTeleportationFactor(double teleportationFactor) {
        this.teleportationFactor = teleportationFactor;
    }


    /**
     * Returns a textual representation of the ranks
     * generated by pagerank
     * @return String
     */
    @Override
    public String ranks() {
        StringBuilder rankOrder = new StringBuilder();
        pageRankScore.entrySet()
                .stream()
                .sorted((entry1, entry2) ->
                {
                    if (entry1.getValue() < entry2.getValue())
                        return 1;
                    else if (entry1.getValue() > entry2.getValue())
                        return -1;
                    else
                        return 0;
                }).collect(Collectors.toList()).forEach( entry -> { rankOrder.append("(" + entry.getKey() + ")");});

        return rankOrder.toString();
    }

    /**
     * Returns the top docID sorted by page rank scores limited by @param limit
     * @param limit
     * @return
     */
    public String top(int limit) {
        StringBuilder top_pages = new StringBuilder();
        List<Map.Entry> pageRankScoreList =
                pageRankScore.entrySet()
                .stream()
                .sorted((entry1, entry2) ->
                {
                    if (entry1.getValue() < entry2.getValue())
                        return 1;
                    else if (entry1.getValue() > entry2.getValue())
                        return -1;
                    else
                        return 0;
                }).collect(Collectors.toList());

        for ( int i = 0 ; i < pageRankScoreList.size() && i < limit ; i++)
            top_pages.append(pageRankScoreList.get(i).getKey()
                    + " "
                    + pageRankScoreList.get(i).getValue()
                    + "\n");

        return top_pages.toString();
    }

    /**
     * Responsible for creating Graph object through
     * it's in-link representation present in a file specified by
     * @param graphFileLocation
     * @throws java.io.IOException
     * @returns void
     */
    private void retrieveGraph(String graphFileLocation) throws Exception {
        GraphBuilder gb = new GraphBuilder();
        gb.setGraphOutputSource(graphFileLocation);
        graph = gb.retrieveGraph();
    }

    /**
     * Runs the page rank algorithm until convergence achieved
     * @throws java.io.IOException
     * @returns void
     * @param perplexityOutputfileLocation
     */
    public void pageRankAlgorithm(String perplexityOutputfileLocation) throws Exception {
        FileUtility.CustomFileWriter customFileWriter = null;
        if (perplexityOutputfileLocation != null)
            customFileWriter = new FileUtility.CustomFileWriter(perplexityOutputfileLocation);
        double defaultScore = (double)1 / graph.getOutLinkMap().size();
        Set<String> sink = null;
        // Initialize initial values
        graph.getInLinkMap().forEach((docID , inLink) -> {
            pageRankScore.put(docID , defaultScore);
        });

        // Continue the rest of the process
        // Collects the sink URL
        sink = graph.getOutLinkMap().entrySet().stream()
                .filter(entry -> { return (entry.getValue().size() == 0);})
                .map(entry -> entry.getKey())
                .collect(Collectors.toSet());

        // Stores the number of consecutive iteration where difference in
        // perplexity is less than 1
        int consecutivePerplexity = 0;
        double oldPerplexity = 0;
        // Absolute difference between newly calculated Perplexity and older value
        double diffPerplexity = 0;
        do {
            double sinkPR = 0;
            Map<String, Double> newPageRankScore = new HashMap<>();
            for ( String docID : sink)  {
                sinkPR += pageRankScore.get(docID);
            }
            // Iterate through all DOC ID to calculate the new PageRank Score
            // for this round
            for ( String docID : pageRankScore.keySet())    {
                double newScore = 0;
                final double DEFAULT_SCORE_TELEPORT = ( 1 - teleportationFactor) / pageRankScore.size();
                newScore = DEFAULT_SCORE_TELEPORT + (teleportationFactor * sinkPR) /  pageRankScore.size();
                for ( String inLinkDocID : graph.getInLinkMap().get(docID)) {
                    if (graph.getOutLinkMap().get(inLinkDocID).size() != 0)
                        newScore += (teleportationFactor * pageRankScore.get(inLinkDocID)) /
                                graph.getOutLinkMap().get(inLinkDocID).size();
                }
                newPageRankScore.put(docID , newScore);
            }
            pageRankScore = newPageRankScore;
            // Calculate Perplexity for the new page rank scores
            double entropy = calculateEntropy();
            double newPerplexity = Math.pow(2 , entropy);
            diffPerplexity = Math.abs( oldPerplexity - newPerplexity);
            oldPerplexity = newPerplexity;
            //System.out.println("old: " + oldPerplexity + " " + "new: " + newPerplexity + " diff: " + diffPerplexity);
            // Writes the perplexity values to a file
            if ( customFileWriter != null)
                customFileWriter.writeLineToFile(String.valueOf(newPerplexity) + "\n");
            // Run the loop until convergence is not achieved.
        } while ( (consecutivePerplexity = nextConsecutivePerplexity(consecutivePerplexity , diffPerplexity))
                != 4);

        // Flushes and closes the file writer if stream is open
        if ( customFileWriter != null)
            customFileWriter.close();
    }

    /**
     * Function returns the next value for consecutive Perplexity
     * @param consecutivePerplexity
     * @param diffPerplexity
     * @return Max value returned is 4. Range : [0 , 4 ]
     */

    private int nextConsecutivePerplexity(int consecutivePerplexity, double diffPerplexity) {
        if (diffPerplexity < 1)
            return ++consecutivePerplexity;
        else
            return 0;
    }

    /**
     * Calculate the Entropy for the current PageRank scores
     * @return void
     */
    private double calculateEntropy() {
        double entropy = 0.0;
        for ( Map.Entry<String,Double> entry : pageRankScore.entrySet())   {
            entropy += - (entry.getValue()) *
                    (Math.log(entry.getValue()) / Math.log(2));
        }
        return entropy;
    }

}
